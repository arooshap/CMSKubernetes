kind: DaemonSet
apiVersion: apps/v1
metadata:
  labels:
    app: scitokens-proxy-server
  name: scitokens-proxy-server
  namespace: auth
spec:
  selector:
    matchLabels:
      app: scitokens-proxy-server
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: scitokens-proxy-server
        env: k8s #k8s#
      annotations:
        prometheus.io/scrape: 'true'
        prometheus.io/port: "9093"
    spec:
      serviceAccountName: scitokens-proxy-server
      terminationGracePeriodSeconds: 60
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      # this daemonset will be applied to all nodes which will have role=autha label
      # kubectl label node <node-name> role=auth --overwrite
      nodeSelector:
        role: auth
      priorityClassName: system-node-critical
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}

      containers:
#       - image: cmssw/auth-proxy-server #imagetag
#       - image: cmssw/auth-proxy-server:0.1.106 #imagetag
#       - image: cmssw/auth-proxy-server:0.1.106-static #imagetag
#       - image: cmssw/auth-proxy-server:0.2.06 #imagetag
      - image: cmssw/auth-proxy-server:0.2.07 #imagetag
        name: scitokens-proxy-server
#         imagePullPolicy: Always
        args:
          - /data/auth-proxy-server
          - -config=/etc/secrets/config.json
          - -scitokens
        resources:
          requests:
            memory: "50Mi"
            cpu: "30m"
          limits:
            memory: "10Gi"
            cpu: "4000m" # we can add higher limit here
        env:
        - name: X509_USER_PROXY
          value: /etc/proxy/proxy
        - name: MY_POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        ports:
        - containerPort: 8843
          name: https
        - containerPort: 9093
          name: metrics
        volumeMounts:
        - name: scitokens-proxy-server-secrets
          mountPath: /etc/secrets
          readOnly: true
        - name: proxy-secrets
          mountPath: /etc/proxy
          readOnly: true
        - name: www-htdocs
          mountPath: /www
        - name: hostcert
          mountPath: /etc/grid-security/hostcert.pem
        - name: hostkey
          mountPath: /etc/grid-security/hostkey.pem
      initContainers:
      - name: htdocs
        image: cmssw/htdocs
        command: ['sh', '-c', 'cp -r /www/* /tmp/htdocs']
        volumeMounts:
        - name: www-htdocs
          mountPath: /tmp/htdocs
#PROD#  - name: logs-cephfs
#PROD#    mountPath: /data/srv/logs/frontend
      volumes:
      - name: scitokens-proxy-server-secrets
        secret:
          secretName: scitokens-proxy-server-secrets
      - name: proxy-secrets
        secret:
          secretName: proxy-secrets
      - name: www-htdocs
        emptyDir: {}
      - name: hostcert
        hostPath:
            path: /etc/grid-security/hostcert.pem
      - name: hostkey
        hostPath:
            path: /etc/grid-security/hostkey.pem
#PROD#- name: logs-cephfs
#PROD#  persistentVolumeClaim:
#PROD#      claimName: logs-cephfs-claim-default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: scitokens-proxy-server
subjects:
- kind: ServiceAccount
  name: scitokens-proxy-server
  namespace: auth
roleRef:
  kind: ClusterRole
  name: scitokens-proxy-server
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: scitokens-proxy-server
  labels:
    k8s-app: scitokens-proxy-server
rules:
- apiGroups: [""] # "" indicates the core API group
  resources:
  - namespaces
  - pods
  verbs:
  - get
  - watch
  - list
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: scitokens-proxy-server
  namespace: auth
  labels:
    k8s-app: scitokens-proxy-server
---
